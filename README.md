# Employee Data Cleaning and Analysis

## Overview
This project performs data cleaning and analysis on an employee dataset using Python and pandas. The goal is to preprocess the raw employee data for further analysis by removing duplicates, validating data fields (such as emails), and handling missing or malformed data.

## Files
- `employee_data-1.csv`: Raw CSV employee data file.
- `employee_cleaned2.csv`: Cleaned version of the employee dataset after preprocessing.
- `Experiment-1-Assignment-2.ipynb`: Jupyter notebook containing the full data cleaning and validation pipeline with code and explanations.

## Data Description
The employee dataset contains the following fields:
- `emp_id`: Employee ID
- `name`: Employee full name
- `email`: Employee email address
- `joining_date`: Date the employee joined the company
- `department`: Employee's department
- `salary`: Employee's salary

## Key Steps in the Notebook
1. **Data Loading**
   - The raw CSV is loaded into a pandas DataFrame.
   - Handles cases when data is read as a single concatenated column and splits it correctly.

2. **Data Cleaning**
   - Duplicate rows are removed.
   - Emails are validated using regular expressions to detect invalid email formats, which are then set to missing.

3. **Data Validation**
   - Missing values in critical fields such as email are identified.
   - Prints and previews of cleaned data are provided after major steps for verification.

## Requirements
- Python 3.x
- pandas
- numpy
- Jupyter Notebook or JupyterLab for running the `.ipynb` file

## How to Use
1. Open the notebook `Experiment-1-Assignment-2.ipynb` in Jupyter Notebook.
2. Ensure the CSV files are in the appropriate directory or adjust the file paths in the notebook accordingly.
3. Run cells sequentially to perform data cleaning and validation.
4. Examine the outputs and cleaned data snapshots generated by the notebook.

## Purpose
This project helps demonstrate practical data preprocessing techniques including handling malformed CSV input, duplicate removal, and input validation which are essential steps before data analysis or machine learning model training.

---

*This README was generated for an employee data cleaning and validation exercise based on the provided notebook and data files.*
