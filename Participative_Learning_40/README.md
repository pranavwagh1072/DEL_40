# Big Data Analysis of Ride-Hailing Services (Uber/Ola) using PySpark

## Overview

This repository contains a complete project for analyzing ride-hailing data generated by Uber and Ola using Apache Spark (PySpark). The project involves handling large datasets of millions of trip records to derive valuable business insights for operational and strategic decision-making.

## Contents

- **Dataset:** `uber_ola_data.csv` - Realistic sample ride-hailing dataset with trip details including pickup/drop locations, timestamps, fare amounts, payment modes, and cities.
- **PySpark Code:** Complete scripts for data loading, cleaning, exploratory analysis, aggregations, time-based analysis, and payment insights.
- **Output CSVs:** Exported CSVs of key query results for reporting and visualization.
- **PDF Reports:** Scripts and examples for converting CSV results into formatted PDF reports.
- **Screenshots:** Visual proof of data processing and outputs at various stages (data cleaning, top locations, peak hours, etc.).
- **Documentation:** This README and a detailed project report explaining methodology and business implications.

## Project Tasks

1. **Data Loading:** Import Uber/Ola dataset with an explicit schema using PySpark.
2. **Data Cleaning:** Convert datetime fields, validate and filter fares, handle missing/invalid data.
3. **Exploratory Queries:** Identify top pickup and drop locations by trip counts.
4. **Aggregations:** Compute total rides, revenue, and average fare per city.
5. **Time-Based Analysis:** Analyze hourly trip distribution to identify peak ride hours.
6. **Payment Insights:** Compare payment types (Cash vs Online) share in all trips.
7. **Higher-Order Business Insights:** Analyze highest revenue-generating cities, peak time optimization, frequent ride pairs for strategic promotions.

## Key Insights

- **Highest revenue city:** Mumbai, driven by dense population, business hubs, and high ride frequency.
- **Peak ride time:** 6 PM, indicating demand surge in evening hours.
- **Most frequent pickup-drop pair:** Vasant Kunj to AIIMS, useful for dynamic pricing and targeted marketing.

## How to Use

1. Clone this repository to your local machine or open in cloud notebook platforms.
2. Upload the dataset (`uber_ola_data.csv`) if running on cloud.
3. Install PySpark (`pip install pyspark`) if not already set up.
4. Run the PySpark scripts in sequence to replicate the analysis.
5. Output CSVs will be saved for further study and presentation.

## Tools and Technologies Used

- Apache Spark (PySpark)
- Python (pandas, matplotlib for PDF conversion)
- CSV data format
- Google Colab or local Spark environment

## License

This project is for educational purposes and academic use.

---


